#!/bin/bash

#    Corey Carter, St. Paul, MN - 09 January 2018
#    This bash script is designed to pull contextual sequence flanking a SNP (variant) from a reference genome.
#    Inputs include: a VCF file, a reference genome, and a user-specified window size for flanking sequence.
#    Example usage ./SNPcontext -i <input VCF> -r <reference genome fasta file> -w <window size>
 

#    The window size for contextual sequence must specified by user.
#    The window is centered on a SNP position read from a VCF file.
#    The program checks for the presence of indels and other variants within the windows flanking each SNP.

#    SNPcontext Version: 2.0.0

scriptPath="$( cd "$( dirname "${BASH_SOURCE[0]}" )" > /dev/null && pwd -P )" ## Location of the script

set -e

# set -eE

# error_catch(){
#     echo -e "There has been an error, The error message has been saved to: ${1} as SNP_CONTEXT_ERROR_LOG.txt\n"
#     exec 2>>"${1}"/SNP_CONTEXT_ERROR_LOG.txt
#     exit 1
# }

# trap 'error_catch "${scriptPath}"' ERR

#     A bash dictionary for input parameters

declare -A projectDic=(
    ["email"]='' #-em
    ["windowLength"]=-9091 #-w
    ["inputFile"]='' #-i
    ["inputLoc"]=''
    ["outputLoc"]='' #-o
    ["filename"]=''
    ["projectName"]='DefaultProjectName' #-p
    ["flanks"]=-9091 #-f
    ["referenceGenome"]='' #-r
    ["OperationalStage"]='vcfTObed'
    ["nMax"]=-9091 ##-n
    ["TempLoc"]=''
    ["tempOut"]=''
    ["allData"]='' #-ad
    ["s3"]=-9091 #-s3
    ["sndMode"]=-9091 #-snd
    ["dropbox"]='' #-dpb
    ["dropboxAuth"]='' #-dpba
    ["github"]='' #-gh
    ["gitUser"]='' #-ghu
    ["gitPass"]='' #-ghp
    ["owner"]='' #-gho
    ["Myrepository"]='' #-ghr
    ["mutationAnalysis"]='' #-ma
    ["nbrOrSpec"]='' #-nbrs
    ["symOrAsy"]='' #-symas
    ["configLocation"]=''
    ["JOB"]='NO_JOB_NOW'
    ["isCmd"]=''
    ["queue"]='' #-qu
    ["graphs"]=-9091 #-graphs
    ## New Job scheduler/Slurm stuff
    ["msi"]='' #-msi ## Old-Implementation
    ["job_specs"]='' #-sp ## Old-Implementation
    ["jobScheduler"]='' # -js Job-scheduler (boolean)
    ["schedulerMode"]=-9091 # -sm Scheduler Mode (int) 
    ["job-time"]='' ## -jt Job time (String HH:MM:SS)
    ["job-nodes"]=-9091 ## -jn Number of nodes (int)
    ["job-memory"]='' ## -jm Memory for whole operation (String)
    ["job-memPerCPU"]='' ## -jmpc Minimum memory per CPU
    ["job-cpuPerTask"]='' ##  -jcpt CPUs per tasks
)

#     A bash list of all possible nucleotide state changes
#     List will be used for iteration and to create output directories and files
##declare -a dirL=('AtoC' 'AtoG' 'AtoT' 'CtoA' 'CtoG' 'CtoT' 'GtoA' 'GtoC' 'GtoT' 'TtoA' 'TtoC' 'TtoG')

##declare -a sndDirL=('AtoT' 'CtoT' 'GtoT' 'TtoA')

declare -a active=()

declare -a activeSND=()

help_display(){ ## UPDATE TO INCLUDE ALL CMDS AND MENTION THE CONFIG FILE IS THE PREFERRED WAY OF OPERATING
    local helpPrintOut=$'\n\tSNP context\n\tList of commands:\n\t------------------------\n'
    helpPrintOut+=$'\n\tSNPcontext -i <input VCF> -o <output> -r <reference genome> -w <window size> -f <flank size> -p <project name> -n <acceptable indel %> -ad <save all data>\n'
    helpPrintOut+=$'\n\t------------------------\n'
    helpPrintOut+=$'\n\t**Input arguments can be in any order.**\n'
    helpPrintOut+=$'\n\t-i [(complete path to VCF file) (the VCF input file)]\n\t-o [(complete path to location) (The output location, if not entered it will default to the same location as your input file.)]'
    helpPrintOut+=$'\n\t-r [(barley or b, soybean or s )(Selects the reference genome, defaults to barley if not specified.)]\n\t-w [(Expansion window size)(The expandable window size around the SNP location, 8 on both ends is the default.)]'
    helpPrintOut+=$'\n\t-p [project name]\n\t-n [max percentage of indels allowed in fasta files]'
    helpPrintOut+=$'\n\t-a [(true/false) Do you want all temp files (vcf, bed and fasta) to be saved in your output directory]'
    helpPrintOut+=$'\n\t-f [(number between 0 and 2) (flank size for aln_to_counts)]'
    helpPrintOut+=$'\n\t-n [(number)(The percentage of accepted indels in the FASTA file)]'
    helpPrintOut+=$'\n\t-ad [(true or false) (Which stands for “all data”, this allows you to keep all intermediate files (split VCFs, BED, new interval BEDs, FASTA files)\n\t    that are normally deleted after processing. Defaults to false, which deletes intermedidate files.)]\n'
    echo "$helpPrintOut"
    exit 0
}

#     Checks for the use of config file
#     The other option is specify all arguments on the command line
config_check(){
    local args=($@)
    if (( "$#" >= 1 )); then # If there is at least one argument
        if (( "$#" == 1 )); then # If there is exactly one argument
            if [[ ${args[0],,} == "--help" ]] || [[ ${args[0],,} == "-h" ]]; then # And that argument is --help or -h
                help_display # Print a usage message
            elif [[ -f "${args[0]}" ]] || [[ ! -z "${args[0]}" ]]; then # And that argument is a file path
                local var=${args##*.} ## Grabs only the extension
                if [[ ${var,,} == "config" ]]; then ## Checks if it's a .config file
                    # echo -e "CONFIG FILE TEST ONE"
                    projectDic["isCmd"]="false"
                    source "${args[0]}"
                    declare -a startList=(
                        ${window_length}
                        ${input_file} # Declares unset variables (NULL), uses -v to check if NULL
                        ${output_location}
                        ${project_name}
                        ${flanks}
                        ${referenceGenome}
                        ${indel_max_amount}
                        ${save_all_data}
                        ${save_S3}
                        ${s3_login}
                        ${s3_password}
                        ${input_email}
			            ${queue}
                        ${sndMode}
                        ${mutation_analysis}
                        ${nbr_or_spectra}
                        ${strand_symmetry_or_asymmetry}
                        ${save_all_data}
                        ${dropbox}
                        ${dropbox_auth}
                        ${github}
                        ${gitUser}
                        ${gitPass}
                        ${Myrepository}
                        ${owner}
                        ${graphs}
                        ## New Job scheduler/Slurm portion
                        ${MSI_Mode} ## Old-Implementation
                        ${job_specs} ## Old-Implementation
                        ${job_scheduler}
                        ${scheduler_mode}
                        ${time}
                        ${nodes}
                        ${memory}
                        ${memory_per_CPU}
                        ${cpus_per_task}
                    )
                    # echo -e "${MSI_Mode}"
                    starter ${startList} # Calls program to assign variables
                else   
                    echo -e "Invalid '.Config' file extension. Exiting..."
                    exit 1
                fi
            else
                echo -e "Invalid single entry, either enter config file with correct path or --help/-h. Exiting..."
                exit 1
            fi
        elif (( "$#" > 1 )); then # If there's more than one argument, assume command-line mode

            # echo -e "CMD TEST ONE"
            projectDic["isCmd"]="true"
            declare -a startList=("$@")
            
            # starter ${startList} # Calls program to assign variables
            starter # Calls program to assign variables
        else 
            echo -e "Invalid entries. Exiting..."
            exit 1
        fi
    else # If there are no arguments at all, show the usage message
        help_display
    fi
}

#     Takes user arguments from command line and assigns values to dictionary keys in 'projectDic'
starter(){ #grabs the arguments
    local frontgate=0
    local indexPos=0
    for i in ${startList[@]}; do # Loop over every argument
        # echo -e "${i}"
        # echo -e "${isCmd}"
        # if [[ "${projectDic["isCmd"]}" == "true" ]] && [[ ${#startList[@]} != ${indexPos} ]]; then # If parameters were entered via command-line mode and we haven't reached the end of the parameters
        if [[ "${projectDic["isCmd"]}" == "true" ]]; then # If parameters were entered via command-line mode and we haven't reached the end of the parameters
            # echo -e "CMD TEST TWO"
            var="${startList[${indexPos}+1]}"
        # elif [[ "${projectDic["isCmd"]}" == "false" ]]; then # If parameters were entered via config file, life is easy
        else
            var="${i}"
        fi
        if [[ "${i,,}" == "-em" ]] || [[ ${input_email} == $i ]] && [[ ${projectDic["email"]} == "" ]]; then # Set the email
            projectDic["email"]="${var}"
            unset input_email
        elif [[ "${i,,}" == "-w" ]] || [[ ${window_length} == $i ]] && ((projectDic["windowLength"] == -9091)); then ##Window expansion size
            # if [[ "$var" =~ ^[0-1000]$ ]] && (( "$var" >= 0 )); then ##Checks if it's a number, max expansion of 10
            if (( "$var" >= 0 )); then ##Checks if it's a number, max expansion of 10
                if (( "$var" > 1000 )); then # Make sure it's under 10 (100?)
                    echo -e "\nwindow size is too large, defaulting to 10."
                    ((projectDic["windowLength"]=10))
                    frontgate=1
                    unset window_length
                else
                    ((projectDic["windowLength"]="${var}"))
                    frontgate=1 
                    unset window_length
                fi     
            else # Imutation_analysisf it's not an integer number, default to 1 (???)
                echo -e "\nPlease enter a valid integer for window expansion size - defaulting to 1.\n"
                projectDic["windowLength"]=1
                frontgate=1 
                unset window_length
            fi
        elif [[ "${i,,}" == "-i" ]] || [[ ${input_file} == $i ]] && [[ ${projectDic["filename"]} == "" ]]; then ##Input file which grabs the input file name, location and complete file path
            if [[ "${var##*.}" == "vcf" ]]; then ##Checks if it's VCF and if file exist
            # if [[ "${var##*.}" == "vcf" ]] && [[ -f "$var" ]]; then ##Checks if it's VCF and if file exist
                # echo -e "${var##*.}"
                projectDic["inputFile"]+="$var"
                projectDic["inputLoc"]+="${var%/*}"
                local filename=${var%.*} ##Removes files extension
                filename=${filename##*/} ##Removes file path
                projectDic["filename"]+="$filename"
                frontgate=1
                unset input_file
            else
                echo -e "\nERROR. Incorrect file input. Check file or directory path. (Input (.vcf) only)\nEXITING...\n"
                exit 1
            fi
        elif [[ "${i,,}" == "-o" ]] || [[ ${output_location} == $i ]] && [[ ${projectDic["outputLoc"]} == "" ]]; then ##Output location info
            if [ -d "$var" ]; then ##Checks if directory exist, if not it will save to input file location
                if [[ "${var: -1}" == "/" ]]; then
                    projectDic["outputLoc"]+="$var"
                else
                    projectDic["outputLoc"]+="$var"/
                fi
                frontgate=1
                unset output_location
            fi
        elif [[ "${i,,}" == "-p" ]] || [[ ${project_name} == $i ]] && [[ ${projectDic["projectName"]} == "DefaultProjectName" ]]; then ##Project name
            projectDic["projectName"]="$var"
            frontgate=1
            unset project_name
        elif [[ "${i,,}" == "-f" ]] || [[ "${flanks}" == $i ]]; then ##Flank sizes for mutation motif's aln_to_counts func
            if [[ "$var" =~ ^[0-2]$ ]]; then ##Checks if it's a number and if it's between 0 and 2, Regex search
                ((projectDic["flanks"]="$var"))
            else
                echo -e "\nFlanks have to be between: 0 - 2. Defaulting to 0.\n"
                projectDic["flanks"]=0
            fi
            frontgate=1
            unset flanks
        elif [[ "${i,,}" == "-r" ]] || [[ ${referenceGenome} == $i ]] && [[ ${projectDic["referenceGenome"]} == "" ]]; then ##Which reference genome needed for FASTA file creation
            if [[ -f "${var}" ]]; then
                projectDic["referenceGenome"]="${var}"
                frontgate=1
                unset referenceGenome
            else
                echo -e "\nEnter a valid reference genome. Exiting...\n"
                exit 1
            fi
        elif [[ "${i}" == "-JOB" ]]; then
            # local var=${args[${indexPos}+1]}
            projectDic["JOB"]="${var}"
            # echo -e "JOB STATUS:"
            # echo -e "${projectDic["JOB"]}"
        elif [[ "${i}" == "-CONFIGLOC" ]]; then
            # local var=${args[${indexPos}+1]}
            projectDic["configLocation"]="${var}"
        elif [[ "${i,,}" == "-n"  ]] || [[ "${indel_max_amount}" == $i ]] && ((projectDic["nMax"] == -9091)); then
            # echo -e "ATTACK_ONE"
            if [[ "${var}" =~ [0-9] ]]; then ##CHECK WITH PETER!!!
                # echo -e "ATTACK"
                if (( "$var" >= 25  && "$var" <= 100 )); then
                    ((projectDic["nMax"]="$var"))
                elif (( "$var" < 25 )); then
                    echo -e "\nMinimum indel threshold is 25. Defaulting to 25% threshold."
                    ((projectDic["nMax"]=25))
                elif (( "$var" > 100 )); then
                    echo -e "\nMaximum indel threshold is 100. Defaulting to 100% threshold."
                    ((projectDic["nMax"]=100))
                fi
                frontgate=1
                unset indel_max_amount     
            else
                echo -e "\nNot a valid indel threshold entry. Defaulting to 25%.\n"
                unset indel_max_amount         
            fi
            # if [[ "$var" =~ ^[0-9]+$ ]]; then
            #     if (( "${var}" >= 0  && "$var" <= 100 )); then
            #         ((projectDic["nMax"]+="$var"))
            #     elif (( "${var}" < 0 )); then
            #         echo -e "\nMinimum N threshold is 1. Defaulting to 1% threshold."
            #         ((projectDic["nMax"]+=1))
            #     elif (( "${var}" > 100 )); then
            #         echo -e "\nMaximum N threshold is 75. Defaulting to 100% threshold."
            #         ((projectDic["nMax"]+=100))
            #     fi
            #     frontgate=1                    
            # fi
        elif [[ "${i,,}" == "-ad"  ]] || [[ ${save_all_data} == $i ]] && [[ ${projectDic["allData"]} == "" ]]; then # Set flag for saving intermediate data
            if [[ "${var,,}" == "true" ]] || [[ "${var,,}" == "false" ]]; then
                projectDic["allData"]="${var,,}"
                frontgate=1
                unset save_all_data
            else
                echo -e "No valid all data entry (true or false), defaulting to false. Only counts tables will be saved."
            fi
        elif [[ "${i,,}" == "-s3" ]] || [[ ${save_S3} == $i ]] && (( "${projectDic["s3"]}" == -9091 )); then # Set flag for saving to S3
            if [[ "${var}" -ge 0 ]] && [[ "${var}" -le 3 ]]; then
                projectDic["s3"]="${var,,}"
                frontgate=1
                unset save_S3
            else
                echo -e "No valid entry for S3 storage (0 to 3), defaulting to false."
                projectDic["s3"]=0
            fi
        elif [[ "${i,,}" == "-dpb" ]] || [[ ${dropbox} == $i ]] && [[ ${projectDic["dropbox"]} == "" ]]; then # Set flag for saving to Dropbox
            if [[ "${var,,}" == "true" ]] || [[ "${var,,}" == "false" ]]; then
                projectDic["dropbox"]="${var,,}"
                frontgate=1
                unset dropbox

            else
                echo -e "No valid entry for Dropbox uploading (true or false), defaulting to false."
            fi
        elif [[ "${i,,}" == "-gh" ]] || [[ ${github} == $i ]] && [[ ${projectDic["github"]} == "" ]]; then # Set flag for saving to Github
            # echo -e "${var,,}"
            if [[ "${var,,}" == "true" ]] || [[ "${var,,}" == "false" ]]; then
                # echo -e "${var,,}"
                projectDic["github"]="${var,,}"
                frontgate=1
                unset github

            else
                echo -e "No valid entry for github uploading (true or false), defaulting to false."
                projectDic["github"]="false"
            fi
        ## New Addition for Slurm Implementation
        elif [[ "${i,,}" == "-js" ]] || [[ ${job_scheduler} == $i ]] && [[ ${projectDic["jobScheduler"]} == "" ]]; then
            if [[ "${var,,}" == "true" ]] || [[ "${var,,}" == "false" ]]; then
                projectDic["jobScheduler"]="${var,,}" ## Saves job scheduler results to the hashmap
            else 
                echo -e "Invalid job scheduler mode, defaulting to false."
                projectDic["jobScheduler"]='false'
                frontgate=1
                unset job_scheduler 
            fi
        elif [[ "${i,,}" == "-sm" ]] || [[ ${scheduler_mode} == $i ]] && [[ ${projectDic["schedulerMode"]} == -9091 ]]; then
            if [[ "${var,,}" -eq 1 ]] || [[ "${var,,}" -eq 2 ]]; then
                projectDic["schedulerMode"]="${var,,}" ## Saves job scheduler results to the hashmap
            else 
                echo -e "Invalid job scheduler mode, 1 = slurm or 2 = PBS - defaulting to false."
                projectDic["jobScheduler"]='false'
                projectDic["jobScheduler"]=0
                frontgate=1
                unset job_scheduler 
            fi
        elif [[ "${i,,}" == "-msi" ]] || [[ ${MSI_Mode} == $i ]] && [[ ${projectDic["msi"]} == "" ]]; then # Set flag for MSI-specific operations
            # echo -e "MSI MODE:\n"
            # echo -e "${var}"
            if [[ "${var,,}" == "true" ]] || [[ "${var,,}" == "false" ]]; then
                # echo -e "${i}"
                projectDic["msi"]="${var,,}"
                frontgate=1
                unset MSI_Mode
            else
                echo -e "No valid entry for MSI mode (true or false), defaulting to false."
                projectDic["msi"]='false'
                frontgate=1
                unset MSI_Mode                
            fi
        elif [[ "${i,,}" == "-ma" ]] || [[ ${mutation_analysis} == $i ]] && [[ ${projectDic["mutationAnalysis"]} == "" ]]; then
            if [[ "${var,,}" == "true" ]] || [[ "${var,,}" == "false" ]]; then
                projectDic["mutationAnalysis"]="${var,,}"
                frontgate=1
                unset mutation_analysis
            else
                echo -e "No valid entry for mutation Analysis mode (true or false), defaulting to false."
                projectDic["mutationAnalysis"]='false'
                frontgate=1
                unset mutation_analysis                
            fi
        elif [[ "${i,,}" == "-nbrs" ]] || [[ ${nbr_or_spectra} == $i ]] && [[ "${projectDic["nbrOrSpec"]}" == '' ]]; then
            if [[ "${var,,}" == "1" ]] || [[ "${var,,}" == "2" ]]; then
                ((projectDic["nbrOrSpec"]="${var,,}"))
                frontgate=1
                unset nbr_or_spectra
            else
                echo -e "No valid entry for nbr or spectra mode (1 or 2), defaulting to nbr."
                ((projectDic["nbrOrSpec"]=1))
                frontgate=1
                unset nbr_or_spectra                
            fi
        elif [[ "${i,,}" == "-symas" ]] || [[ ${strand_symmetry_or_asymmetry} == $i ]] && [[ "${projectDic["symOrAsy"]}" == '' ]]; then
            if [[ "${var,,}" == "1" ]] || [[ "${var,,}" == "2" ]]; then
                ((projectDic["symOrAsy"]="${var,,}"))
                frontgate=1
                unset strand_symmetry_or_asymmetry
            else
                echo -e "No valid entry for strand symmetry(1, 2), defaulting to strand-symmetry (1)."
                ((projectDic["symOrAsy"]=1))
                frontgate=1
                unset strand_symmetry_or_asymmetry                
            fi
        elif [[ "${i,,}" == "-graphs" ]] || [[ ${graphs} == $i ]] && (( "${projectDic["graphs"]}" == -9091 )); then #
            if [[ "${var}" -eq 1 ]] || [[ "${var}" -eq 2 ]] || [[ "${var}" -eq 3 ]]; then
                projectDic["graphs"]="${var,,}"
                frontgate=1
                unset graphs
            else
                echo -e "No valid entry for graphing (1 to 3), defaulting to graphing both direction tables and combined counts table."
                projectDic["graphs"]=1
            fi
        elif [[ "${i,,}" == "-snd" ]] || [[ ${sndMode} == $i ]] && (( "${projectDic["sndMode"]}" == -9091 )); then #
            if [[ "${var}" -eq 1 ]] || [[ "${var}" -eq 2 ]]; then
                projectDic["sndMode"]="${var,,}"
                frontgate=1
                unset graphs
            else
                echo -e "No valid entry for SND mode, defaulting to off.\n"
                projectDic["sndMode"]=0
            fi
        elif [[ "${i,,}" == "-dpba" ]] || [[ ${dropbox_auth} == $i ]] && [[ ${projectDic["dropboxAuth"]} == "" ]]; then # Set variable for Dropbox authorization
            projectDic["dropboxAuth"]="${var}"
            frontgate=1
            unset dropbox_auth
        elif [[ "${i,,}" == "-ghu" ]] || [[ ${gitUser} == $i ]] && [[ ${projectDic["gitUser"]} == "" ]]; then # Set variable for Git username
            projectDic["gitUser"]="${var,,}"
            frontgate=1
            unset gitUser
        elif [[ "${i,,}" == "-ghp" ]] || [[ ${gitPass} == $i ]] && [[ ${projectDic["gitPass"]} == "" ]]; then # Set variable for Github password
            projectDic["gitPass"]="${var,,}"
            frontgate=1
            unset gitPass
        elif [[ "${i,,}" == "-gho" ]] || [[ ${owner} == $i ]] && [[ ${projectDic["owner"]} == "" ]]; then # Set variable for Git repository owner
            projectDic["owner"]="${var,,}"
            frontgate=1
            unset owner
        elif [[ "${i,,}" == "-ghr" ]] || [[ ${Myrepository} == $i ]] && [[ ${projectDic["Myrepository"]} == "" ]]; then # Set variable for Git repository
            projectDic["Myrepository"]="${var,,}"
            frontgate=1
            unset Myrepository
        elif [[ "${i,,}" == "-qu"  ]] || [[ ${queue} == $i ]]; then
            # There's no need to check if the queue is valid since PBS does that automatically upon job submission
            projectDic["queue"]="${var,,}"
            frontgate=1
            unset queue
        fi
        ((indexPos+=1))
    done
    if [[ "${frontgate}" -le 0 ]]; then # If none of the above if statements were true, then something was invalid
        echo -e "\nPlease enter valid arguments. None were valid.\n"
        exit 1
    fi
    if [[ ${projectDic["inputFile"]} == '' ]]; then # If after setting all the parameters, we don't have a project directory, exit
        echo -e "\nNo input file or working directory specified.\nEXITING...\n"
        exit 1
    fi
    if [[ -z ${projectDic["outputLoc"]} ]] && [[ ${projectDic["inputFile"]} != '' ]]; then # If the output location is invalid, use the input location
        echo -e "\nNot a valid output location. Re-routing to input file location.\n"
        projectDic["outputLoc"]+=${projectDic["inputLoc"]}
    fi
    if [[ ${projectDic["referenceGenome"]} == "" ]]; then # If we don't have a reference genome, that's a problem
        echo -e "No reference genome entered. Exiting..."
        exit 1
    fi
    if (( ${projectDic["flanks"]} > ${projectDic["windowLength"]} )); then # If the flank size is larger than the window size, expand the window size
        echo -e "Flank larger than window expansion, expanding window size to flank size of ${projectDic["flanks"]}"
        projectDic["windowLength"]=${projectDic["flanks"]}
    fi
    if [[ "${projectDic["dropbox"],,}" == "true" ]] && [[ "${projectDic["dropboxAuth"]}" == '' ]]; then # If you want to Dropbox, but don't give an auth code, that's a problem
        echo -e "Dropbox mode is set to true but there is no generated access token provided."
        echo -e "Changing Dropbox mode to false"
        projectDic["dropbox"]="false"
    fi
    if [[ "${projectDic["s3"]}" -eq 2 ]] || [[ "${projectDic["s3"],,}" -eq 3 ]]; then # If you want to S3, but we can't, that's a problem
        if [[ ! -d ~/.aws ]] && (( "${projectDic["s3"]}" == 2 )); then 
            echo -e "AWS isn't set up in your home directory."
            echo -e "Changing S3 mode to false"
            projectDic["s3"]=0
        elif [[ ! -d ~/.aws ]] && (( "${projectDic["s3"]}" == 3 )); then 
            echo -e "AWS isn't set up in your home directory."
            echo -e "Saving only to MSI's S3.\n"
            projectDic["s3"]=1
        fi
    fi
    if [[ "${projectDic["github"],,}" == "true" ]]; then # Make sure we have all the things to do Github properly
        if [[ "${projectDic[[ ["gitUser"]}" == '' ]] || /
        [[ "${projectDic["gitPass"]}" == '' ]] || /
        [[ "${projectDic["Myrepository"]}" == '' ]]; then
            echo -e "Github input parameters not filled out correctly, defaulting Github to false"
            echo -e "Changing Github mode to false"
            projectDic["github"]="false"
        fi
        if [[ "${projectDic["owner"]}" == "" ]]; then
            echo -e "Owner of the Github repository was not specified, defaulting to your username."
            projectDic["owner"]="${projectDic["gitUser"]}"
        fi
    fi
    unset startList
}

#    Loading modules on UMN MSI system. Three of the four are maintained by Morrell Lab (Corey Carter).
moduleLoader(){ #Load modules needed for operations
    if [[ "${projectDic["msi"],,}" == 'true' ]]; then
    
        # echo -e "\nExporting Morrell lab modules to your MODULEPATH.\n"
        export MODULEPATH=/panfs/roc/groups/9/morrellp/public/Modules:$MODULEPATH
        module load python3_ML/3.6.4
        module load bedops_ML/2.4.35 
        module load bedtools_ML/2.28.0
	    module load pypy_ML/3.6
    else
        declare -A testlisting=( ["python3"]=3.6.4 ["bedops"]=2.4.35 ["bedtools"]=2.23.0 )
        for inProgram in ${!testlisting[@]}; do # Make sure that all dependencies are functional
            if [[ -x $(command -v "${inProgram}") ]]; then
                if [[ "${inProgram}" == "python3" ]] && [[ $(python3 -c 'import sys; print(sys.version_info[0:2])') == '(3, 6)' ]]; then
                    if [[ $(python3 -c 'import sys; sys.tracebacklimit=0; import mutation_motif') == "ModuleNotFoundError: No module named mutation_motif" ]]; then
                        echo -e "Python module Mutation Motif is not installed. Please follow the link for instructions: (https://bitbucket.org/pycogent3/mutationmotif).\n"
                    fi
                    if (( "${projectDic["s3"]}" > 0 )) && (( "${projectDic["s3"]}" <= 3 )); then
                        if [[ ! $(python3 -c 'import sys; sys.tracebacklimit=0; import boto3') == "ModuleNotFoundError: No module named boto3" ]]; then
                            echo -e "Python module boto3 (S3) is not installed. Please pip install boto3 for Amazon save S3 support. Use command: pip3 install boto3\n"
                        fi
                    fi
                    if [[ "${projectDic["dropbox"]}" == "true" ]] && [[ ! $(python3 -c 'import sys; sys.tracebacklimit=0; import dropbox') == "ModuleNotFoundError: No module named dropbox" ]]; then
                        echo -e "Python module for dropbox is not installed. Please pip install dropbox for dropbox save support. Use command: pip3 install dropbox\n"
                    fi
                elif [[ ! "${inProgram}" == "python3" ]] && [[ $(python3 -c 'import sys; print(sys.version_info[0:2])') != '(3, 6)' ]]; then
                    echo -e "Python version out of date. Please install Python 3.6.x.\n"
                fi
            else
                echo -e "${inProgram} is not installed, please install ${inProgram} version: ${testlisting[$inProgram]}.\n"
            fi
        done
    fi

}

#    Performing vcf to bed conversion using bedops 'vcf2bed' function
fileConverter(){
    if [ "${projectDic[OperationalStage]}" == "vcfTObed" ]; then ##Key and new input LOCATION
        # local temp="${projectDic["tempOut"]}"SPLITVCF/
        local temp="${projectDic["tempOut"]}""${1}"
        local splitDir=("${temp}"*_split_"${projectDic[filename]}".vcf*)
        for gene in "${splitDir[@]}"; do
            local targetVCF="${gene%.*}"
            targetVCF="${targetVCF##*/}"
            vcf2bed < "${gene}" > "${projectDic["tempOut"]}""${2}""${targetVCF}".bed & ##sort later
        done
        wait
        projectDic[OperationalStage]="bedTOfasta"
    #    Takes a reference genome and bed file and generates small fasta files from reference genome intervals
    elif [ "${projectDic[OperationalStage]}" == "bedTOfasta" ]; then
        local temp="${projectDic["tempOut"]}""${1}"
        local splitDir=("${temp}"*"${projectDic[filename]}"_new_interval.bed*)
        for gene in "${splitDir[@]}"; do
            local targetBED="${gene%.*}"
            targetBED="${targetBED##*/}"
            targetBED=${targetBED:0:4}
            # bedtools getfasta -fi "${projectDic["referenceGenome"]}" -bed "${gene}" -fo "${projectDic["tempOut"]}"FASTA_SPLIT/"${targetBED}"_"${projectDic[filename]}".fasta &
            bedtools getfasta -fi "${projectDic["referenceGenome"]}" -bed "${gene}" -fo "${projectDic["tempOut"]}""${2}""${targetBED}"_"${projectDic[filename]}".fasta &
        done
        wait
        projectDic[OperationalStage]="alnToCounts"
    elif [ "${projectDic[OperationalStage]}" == "alnToCounts" ]; then
        # local temp="${projectDic["tempOut"]}"FASTA_SPLIT/
        local temp="${projectDic["tempOut"]}""${1}"
        local splitDir=("${temp}"*_"${projectDic[filename]}".fasta*)
        echo -e "Creating counts tables..."
        for gene in "${splitDir[@]}"; do
            local countfile="${gene%.*}"
            countfile="${countfile##*/}"
            local geneDirection=${countfile:0:4}
            aln_to_counts --align_path "${gene}" --output_path "${projectDic[outputLoc]}""${2}" --flank_size "${projectDic[flanks]}" --direction "${geneDirection}" -F > /dev/null
            # mv "${projectDic[outputLoc]}"COUNTS_TABLES/"${countfile}".txt "${projectDic[outputLoc]}"COUNTS_TABLES/"${geneDirection}"_"${projectDic[filename]}".txt
            mv "${projectDic[outputLoc]}""${2}"*.log* "${projectDic[outputLoc]}""${2}"/LOGS/"${geneDirection}"_"${projectDic[filename]}".log ##FIX Unique Log ID'S    
            active+=("${geneDirection}")
        done
        projectDic["OperationalStage"]="allCounts"
    elif [ "${projectDic[OperationalStage]}" == "allCounts" ]; then
        echo -e "Creating combined tables..."
        cd "${projectDic[outputLoc]}"COUNTS_TABLES/
        mkdir "${projectDic[outputLoc]}"COUNTS_TABLES/COMBINED_COUNTS
        all_counts -c "*.txt*" -o "${projectDic[outputLoc]}"COUNTS_TABLES/ --strand_symmetric > /dev/null
        # all_counts -c "*.txt*" -o "${projectDic[outputLoc]}"COUNTS_TABLES/ --strand_symmetric
        mv "${projectDic[outputLoc]}"COUNTS_TABLES/combined_counts.txt "${projectDic[outputLoc]}"COUNTS_TABLES/COMBINED_COUNTS/"${projectDic[filename]}"_combined_counts.txt
        mv "${projectDic[outputLoc]}"COUNTS_TABLES/combined_counts.log "${projectDic[outputLoc]}"COUNTS_TABLES/COMBINED_COUNTS/"${projectDic[filename]}"_combined_counts.log
        projectDic["OperationalStage"]="graphSingle"
    elif [ "${projectDic[OperationalStage]}" == "graphSingle" ]; then
        if [ "${projectDic["mutationAnalysis"]}" == "true" ]; then
            if [[ "${projectDic["nbrOrSpec"]}" == "1" ]]; then
                nOrS="nbr"
            elif [[ "${projectDic["nbrOrSpec"]}" == "2" ]]; then
                nOrS="spectra"
            else
                nOrS="nbr"
            fi
            cd "${projectDic[outputLoc]}""${2}"
            if [[ "${projectDic["graphs"]}" == 1 ]] || [[ "${projectDic["graphs"]}" == 2 ]]; then
                for geneDirection in "${active[@]}"; do
                    mkdir "${projectDic[outputLoc]}""${2}""${geneDirection}"
                    ## No "--strand_symmetry" unless "all_counts" is called
                    mutation_analysis nbr -1 "${projectDic[outputLoc]}""${1}""${geneDirection}"_"${projectDic[filename]}".txt -o "${projectDic[outputLoc]}""${2}""${geneDirection}"
                done
            fi
            projectDic["OperationalStage"]="graphCombined"
        elif [ "${projectDic[OperationalStage]}" == "graphCombined" ]; then
            if [[ "${projectDic["nbrOrSpec"]}" == "1" ]]; then
                nOrS="nbr"
            elif [[ "${projectDic["nbrOrSpec"]}" == "2" ]]; then
                nOrS="spectra"
            else
                nOrS="nbr"
            fi
            if [[ "${projectDic["graphs"]}" == 1 ]] || [[ "${projectDic["graphs"]}" == 3 ]]; then
                if [[ "${projectDic["symOrAsy"]}" == "2" ]] && [[ "${projectDic["nbrOrSpec"]}" == "1" ]]; then
                    sOrA=" "
                else
                    sOrA="--strand_symmetry"
            
                fi
                mkdir "${projectDic[outputLoc]}"MUTATION_ANALYSIS/COMBINED_COUNTS
                mutation_analysis "${nOrS}" -1 "${projectDic[outputLoc]}"COUNTS_TABLES/COMBINED_COUNTS/"${projectDic[filename]}"_combined_counts.txt -o "${projectDic[outputLoc]}"MUTATION_ANALYSIS/COMBINED_COUNTS "${sOrA}"
            fi
            echo -e "Mutation Analysis complete...\n"
            projectDic["OperationalStage"]="DONE..."
        else
            projectDic["OperationalStage"]="DONE..."
        fi
    fi

}

#    Creates output directories
dirStructure(){
    DATE=`date +"%m%d%Y-%H%M"`
    mkdir "${projectDic["outputLoc"]}""${projectDic["projectName"]^^}"_"${DATE}"/
    projectDic["outputLoc"]="${projectDic["outputLoc"]}""${projectDic["projectName"]^^}"_"${DATE}"/
    mkdir "${projectDic[outputLoc]}"COUNTS_TABLES
    mkdir "${projectDic[outputLoc]}"COUNTS_TABLES/LOGS
    mkdir "${projectDic[outputLoc]}"MUTATION_ANALYSIS
    if [[ ${projectDic["allData"]} == "true" ]]; then
        mkdir "${projectDic[outputLoc]}"SPLITVCF
        mkdir "${projectDic[outputLoc]}"FASTA_SPLIT
        mkdir "${projectDic[outputLoc]}"BED_SPLIT
        if [[ "${projectDic[sndMode]}" -eq 1 ]]; then
            mkdir "${projectDic[outputLoc]}"SPLITVCF/SND_VCF
        fi
        projectDic["tempOut"]="${projectDic[outputLoc]}"
    elif [[ ${projectDic["allData"]} == "false" ]]; then
        projectDic["TempLoc"]+=$(mktemp -d)
        mkdir "${projectDic[TempLoc]}"/SPLITVCF
        mkdir "${projectDic[TempLoc]}"/FASTA_SPLIT
        mkdir "${projectDic[TempLoc]}"/BED_SPLIT
        if [[ "${projectDic[sndMode]}" -eq 1 ]]; then
            mkdir "${projectDic[TempLoc]}"/SPLITVCF/SND_VCF
        fi
        projectDic["tempOut"]="${projectDic["TempLoc"]}"/
    fi
}
#    Checks for UMN or Amazon S3, 1=UMN S3, 2=Amazon S3, 3=Amazon & UMN S3
s3Saver(){
    if [[ ${projectDic["isCmd"]} == "false" ]] && [[ ${projectDic["configLocation"]} == '' ]]; then
        config="$@"
    elif [[ ${projectDic["isCmd"]} == "true" ]] && [[ ${projectDic["configLocation"]} != '' ]]; then
        config=${projectDic["configLocation"]}
    else
        config="none"
    fi

    if (( "${projectDic["s3"]}" != 0 )); then
        if (( "${projectDic["s3"]}" == 1 )) || (( "${projectDic["s3"]}" == 3 )); then
            if s3cmd mb s3://${projectDic["projectName"],,} > /dev/null; then
                echo -e "\nS3 bucket created..."
                echo -e "Transfering files..."
                if s3cmd put --recursive "${projectDic["outputLoc"]}"COUNTS_TABLES/ s3://${projectDic["projectName"],,} 2>/dev/null; then
                    s3cmd put ${config} s3://${projectDic["projectName"],,} 2>/dev/null
                    echo -e "\nFiles transfered to MSI S3...\n"
                else
                    echo -e "\nMSI S3 file transfer failed...\n"
                fi
            else
                echo -e "S3 bucket creation failed."
            fi
        fi
        if (( "${projectDic["msi"]}" == 2 )) || (( "${projectDic["msi"]}" == 3 )); then

            isCmd=${projectDic["isCmd"]} config=${config} project=${projectDic["projectName"]} output="${projectDic["tempOut"]}" python3.6 - << END_OF_TRANSFER
#    Here we go in Python 3
#    Start by loading a bunch of required libraries
#    Only necessary to upload output to Amazon S3
import boto3
import os
import io
import datetime

def s3sentit(inputLoc, project, isCmd, config):
    date = datetime.datetime.now()
    allFiles={}
    currentDir = inputLoc
    s3 = boto3.resource('s3')
    my_session = boto3.session.Session()
    userRegion = my_session.region_name
    newFolder = project + "-countfiles" + "-" + date.strftime("%Y%m%d") + "-" + date.strftime("%H%M")
    s3.create_bucket(Bucket=newFolder, CreateBucketConfiguration={'LocationConstraint': userRegion})
    countsDirs = next(os.walk(currentDir + "COUNTS_TABLES/"))[1]
    for files in countsDirs:
        bottomDirs = currentDir + "COUNTS_TABLES/" + files + "/"
        [ allFiles.update({f: [bottomDirs + f, files]}) for f in os.listdir(bottomDirs) if os.path.isfile(bottomDirs + f) ]
        
    for file, path in allFiles.items():
        with open(path[0], "rb") as fileIO:
            myPath = path[1] + "/" + file
            s3.Object(newFolder, myPath).upload_fileobj(fileIO)                  
    if(config != "none"):
        out=''
        with open(config, "r") as configScanner:
            out_buffer = io.BytesIO()
            line_counter = 0  
            for i in configScanner.readlines():
                if(i.startswith("dropbox_auth")):
                    out="dropbox_auth=***REDACTED*** removed to maintain account security.\n"
                elif(i.startswith("gitPass")):
                    out="gitPass=***REDACTED*** removed to maintain account security.\n"
                elif(i.startswith("input_email")):
                    out="input_email=***REDACTED*** removed to maintain account security.\n"
                else:
                    out=i
                out_buffer.write(out.encode())
                line_counter += 1
            out_buffer.seek(0)
            s3.Object(newFolder, "context.config").upload_fileobj(out_buffer)
            out_buffer.close()    

def bashimports():
    project = str(os.environ['project'])
    inputLoc = str(os.environ['output'])
    isCmd = str(os.environ['isCmd'])
    config = str(os.environ['config'])
    return(inputLoc, project, isCmd, config)

def main():
    output, project, isCmd, config=bashimports()
    s3sentit(output, project, isCmd, config)

main()

END_OF_TRANSFER

        echo -e "Amazon S3 transfer complete.\n"

        fi

    fi

    

}
#    Module to upload output to Dropbox
dropboxSaver(){
    if [[ ${projectDic["isCmd"]} == "false" ]] && [[ ${projectDic["configLocation"]} == '' ]]; then
        config="$@"
    elif [[ ${projectDic["isCmd"]} == "true" ]] && [[ ${projectDic["configLocation"]} != '' ]]; then
        config=${projectDic["configLocation"]}
    else
        config="none"
    fi

    isCmd=${projectDic["isCmd"]} config=${config} project=${projectDic["projectName"]} output="${projectDic["tempOut"]}" dbAuth="${projectDic["dropboxAuth"]}" python3.6 - << END_OF_TRANSFER

import dropbox
import os
import datetime

def dpsentit(inputLoc, project, dbAuth, isCmd, config):
    date = datetime.datetime.now()
    allFiles={}
    currentDir = inputLoc  
    dbx = dropbox.Dropbox(dbAuth)
    newFolder = "/" + project + "-countfiles" + "-" + date.strftime("%Y%m%d") + "-" + date.strftime("%H%M")
    countsDirs = ""
    for path in os.walk(inputLoc + "COUNTS_TABLES/"):
        countsDirs += path + " "
    # countsDirs = next(os.walk(inputLoc + "COUNTS_TABLES/"))[1]
    print(countsDirs)
    for files in countsDirs:
        bottomDirs = currentDir + "COUNTS_TABLES/" + files + "/"        
        [ allFiles.update({f: [bottomDirs + f, files]}) for f in os.listdir(bottomDirs) if os.path.isfile(bottomDirs + f) ]
    for file, path in allFiles.items():
        with open(path[0], 'rb') as sendDP:
            myPath= newFolder + "/" + path[1] + "/" + file
            dbx.files_upload(sendDP.read(), myPath, mode=dropbox.files.WriteMode.overwrite)

    if(config != "none"):
        out=''
        with open(config, "r") as configScanner:
            for i in configScanner.readlines():
                if(i.startswith("dropbox_auth")):
                    out+="dropbox_auth=***REDACTED*** removed to maintain account security.\n"
                elif(i.startswith("gitPass")):
                    out+="gitPass=***REDACTED*** removed to maintain account security.\n"
                elif(i.startswith("input_email")):
                    out+="input_email=***REDACTED*** removed to maintain account security.\n"
                else:
                    out+=i            
        outBytes = out.encode()
        dbx.files_upload(outBytes, newFolder + "/context.config", mode=dropbox.files.WriteMode.overwrite)

def bashimports():
    dbAuth = str(os.environ['dbAuth'])    
    project = str(os.environ['project'])
    inputLoc = str(os.environ['output'])
    isCmd = str(os.environ['isCmd'])
    config = str(os.environ['config'])
    return(inputLoc, project, dbAuth, isCmd, config)

def main():
    inputLoc, project, dbAuth, isCmd, config=bashimports()
    dpsentit(inputLoc, project, dbAuth, isCmd, config)
    
main()

END_OF_TRANSFER

    echo -e "Dropbox transfer complete.\n"

}
#    Upload output to GitHub
gitHubSendIt() {
    if [[ ${projectDic["isCmd"]} == "false" ]] && [[ ${projectDic["configLocation"]} == '' ]]; then
        config="$@"
    elif [[ ${projectDic["isCmd"]} == "true" ]] && [[ ${projectDic["configLocation"]} != '' ]]; then
        config=${projectDic["configLocation"]}
    else
        config="none"
    fi

           isCmd=${projectDic["isCmd"]} config=${config} project=${projectDic["projectName"]} output="${projectDic["tempOut"]}" gitUser="${projectDic["gitUser"]}" gitPass="${projectDic["gitPass"]}" repo="${projectDic["repo"]}" gitowner="${projectDic["gitowner"]}" python3.6 - << END_OF_TRANSFER

#    Python 3 for GitHub upload
import os
import github3
import datetime

def githubSend(inputLoc, project, gitUser, gitPass, Myrepository, owner, isCmd, config):
    date = datetime.datetime.now() 
    allFiles={}
    currentDir = inputLoc

    gh = github3.login(username=gitUser, password=gitPass)
    repo = gh.repository(owner=owner, repository=Myrepository)

    newFolder = project + "-countfiles" + "-" + date.strftime("%Y%m%d") + "-" + date.strftime("%H%M")
    countsDirs = next(os.walk(currentDir + "COUNTS_TABLES/"))[1]

    for files in countsDirs:
        bottomDirs = currentDir + "COUNTS_TABLES/" + files + "/"   
        [ allFiles.update({f: [bottomDirs + f, files]}) for f in os.listdir(bottomDirs) if os.path.isfile(bottomDirs + f) ]
    
    for file, path in allFiles.items():
        with open(path[0], "rb") as fileIO:
            direction = fileIO.read()
        myPath= newFolder + "/" + path[1] + "/" + file
        repo.create_file(path=myPath, message="Uploading " + file, content=direction)
    
    if(config != "none"):
        out=''
        with open(config, "r") as configScanner:
            for i in configScanner.readlines():
                if(i.startswith("dropbox_auth")):
                    out+="dropbox_auth=***REDACTED*** removed to maintain account security.\n"
                elif(i.startswith("gitPass")):
                    out+="gitPass=***REDACTED*** removed to maintain account security.\n"
                elif(i.startswith("input_email")):
                    out+="input_email=***REDACTED*** removed to maintain account security.\n"
                else:
                    out+=i
        outBytes = out.encode()
        repo.create_file(path=newFolder + "/context.config", message="Uploading Config file", content=outBytes)

def bashimports():
    project = str(os.environ['project'])
    inputLoc = str(os.environ['output'])
    gitUser = str(os.environ['gitUser'])
    gitPass = str(os.environ['gitPass'])
    Myrepository = str(os.environ['repo'])
    owner = str(os.environ['gitowner'])
    isCmd = str(os.environ['isCmd'])
    config = str(os.environ['config'])  
    return(inputLoc, project, gitUser, gitPass, Myrepository, owner, isCmd, config)

def main():
    inputLoc, project, gitUser, gitPass, Myrepository, owner, isCmd, config = bashimports()
    githubSend(inputLoc, project, gitUser, gitPass, Myrepository, owner, isCmd, config)

main()

END_OF_TRANSFER

    echo -e "Counts table data and config file sent to your github"

}

#    This is Python 3 code embedded in the bash script
#    Expands coverage windows based on user-specified intervals
#    Also checks for "Type One" and "Type Two" overlaps
#    A "Type One overlap" is another SNP within immediate contextual sequence
#    A "Type Two overlap" is another SNP within the expanded flanking contextual sequencing
pythonBEDScanner(){
    inputFile="${projectDic["inputFile"]}" baseOut="${projectDic["outputLoc"]}" outputLoc="${projectDic["tempOut"]}" filename="${projectDic["filename"]}" projectName="${projectDic["projectName"]}" interval="${projectDic["windowLength"]}" geneDir="$geneDir" sndMode="$sndLocal" pypy3.6 - <<END_OF_PYTHON
    
import os
import re
import subprocess
from itertools import chain
import datetime

def bedMapperOld(interval, outputLoc, projectName, filename, geneDir, sndMode, bedType):
    output = str(subprocess.check_output(['wc', '-m', outputLoc + bedType + geneDir + "_split_" + filename + ".bed"]))
    length = re.findall(r'\d+', output)
    length = int(length[0])
    bedMapper=bytearray()
    masterList=[]
    sub=[] ##FOR BEDMAPPER
    temp=[] ##FOR MASTERLIST
    final=''
    with open(outputLoc + bedType + geneDir + "_split_" + filename + ".bed", "rb") as bed_test: ##Change to input variables
        for i in range(length):
            element = bed_test.read(1).decode("ascii")
            if((element != '\t') and (element != '\n')):
                final = final + element
            elif((element == '\t') and (element != '\n')):
                sub.append(final)
                final=''
                sub.append(element)
            if(element == "\n"):
                sub.append(final)
                sub.append(element)
                sub[2] = str(int(sub[2]) - interval)
                sub[4] = str(int(sub[4]) + interval)         
                a = sub[2]
                b = sub[4]
                temp.append(int(a))
                temp.append(int(b))
                temp.sort()

                ## Adding this conditional to remove duplicates in the bed file
                # if(temp not in masterList):
                #     bedMapper.extend(''.join(sub).encode("utf-8"))
                #     masterList.append(temp)

                bedMapper.extend(''.join(sub).encode("utf-8"))
                masterList.append(temp)
                
                #else:
                #    print("Duplicate intervals between " + a + " to " + b + " found, removing from bed file. Duplicate positions prevents mutation analysis count tables.")
                
                final=''
                sub=[] ## was sub=[]
                temp=[] ## was sub=[]
    with open(outputLoc + bedType + geneDir + "_" + filename + "_new_interval.bed", "wb") as newBed: ##Change to input variables ## Moved indent in
        newBed.write(bedMapper)
    
    return(masterList)

def bedMapper(interval, outputLoc, projectName, filename, geneDir, sndMode, bedType):
    masterList=[]
    with open(outputLoc + bedType + geneDir + "_split_" + filename + ".bed", "rb") as bed_test, open(outputLoc + bedType + geneDir + "_" + filename + "_new_interval.bed", "wb+") as newBed:
        gate = True
        tabDelimter = 0
        finalOut = b''
        leftNum = ""
        rightNum = ""
        while(gate):
            element = bed_test.read(1)
            if(not element):
                gate = False
                continue
            if(chr(ord(element)) == '\t'):
                tabDelimter += 1
            elif(tabDelimter == 0):
                finalOut += element
            elif(tabDelimter == 1):
                leftNum += chr(ord(element))
            elif(tabDelimter == 2):
                rightNum += chr(ord(element))
            elif(tabDelimter == 3):
                leftNum = str(int(leftNum) - interval)
                rightNum = str(int(rightNum) + interval)
                # if([int(leftNum), int(rightNum)] not in masterList): # TEMP, FOR TESTING - WILL REMOVE AFTER TESTING IS FINISHED
                #     masterList.append([int(leftNum), int(rightNum)])
                #     newBed.write(finalOut + b'\t' + leftNum.encode("utf-8") + b'\t' + rightNum.encode("utf-8") + b'\t' + bed_test.readline())
                # else:
                #     bed_test.readline()

                masterList.append([int(leftNum), int(rightNum)])
                newBed.write(finalOut + b'\t' + leftNum.encode("utf-8") + b'\t' + rightNum.encode("utf-8") + b'\t' + bed_test.readline())
                tabDelimter = 0
                finalOut = b''
                leftNum = ""
                rightNum = ""
    return(masterList)

def binaryIntersect(expandedList, interval, outputLoc, projectName, filename, geneDir, baseOut):
    gateA=True
    gateB=True
    now = datetime.datetime.now()
    results = '\n**********************\nTYPE ONE and TYPE TWO CHECKS FOR: ' + geneDir + " ON " + now.strftime("%Y-%m-%d, %H:%M") + '\n----------------------------------------------------\n' ##ADD PROJECT NAME TO THIS
    resultsA = '\n**' + geneDir + ' TYPE ONE: OVERLAPS INTO ORIGINAL SNPs**\n------------------------------------\n'
    resultsB = '\n**' + geneDir + ' TYPE TWO: OVERLAPS INTO SNP EXPANSION WINDOWS**\n-------------------------------------\n'
    for i in range(len(expandedList)-1): #Checks for Type One SNP overlaps (ORIGINAL INTERVAL CHECK)
            a=expandedList[i][0] ##A= left side
            b=expandedList[i][1] ##B= right side
            subTA=expandedList[i+1][0]-(interval) ##TYPE ONE SWITCHED FROM - TO +
            subTB=expandedList[i+1][1]+(interval) ##TYPE ONE SWITCHED FROM - TO +
            subMA=expandedList[i+1][0] ##TYPE TWO
            subMB=expandedList[i+1][1] ##TYPE TWO
            binary=[0,0,0,0]
            binaryMB=[0,0,0,0]
            if(a <= subTA):
                binary[0]=1
            if(a <= subTB):
                binary[1]=1
            if(b >= subTA):
                binary[2]=1
            if(b >= subTB):
                binary[3]=1
            if(a <= subMA): ##
                binaryMB[0]=1
            if(a <= subMB):
                binaryMB[1]=1
            if(b >= subMA):
                binaryMB[2]=1
            if(b >= subMB):
                binaryMB[3]=1
            if((binary != [1,1,0,0]) and (binary != [0,0,1,1])):
                gateA=False
                if(binary == [0,1,1,0]):
                    resultsA+="\n--TYPE ONE at : " + str(a) + "-" + str(b) + " SNP is encapsulated within " + str(subTA) + "-" + str(subTB) + '.'
                elif(binary == [1,1,1,1]):
                    resultsA+="\n--TYPE ONE at : " + str(a) + "-" + str(b) + " is equal or encapsulating " + str(subTA) + "-" + str(subTB) + '.'
                elif((binary == [1,1,1,0]) or (binary == [0,1,1,1])):
                    if(binary == [1,1,1,0]):
                        resultsA+="\n--TYPE ONE at : " + str(a) + "-" + str(b) + " is overlapping with " + str(subTA) + "-" + str(subTB) + ". on the right, between " + str(b) + " and " + str(subTA) + '.'
                    elif(binary == [0,1,1,1]):
                        resultsA+="\n--TYPE ONE at : " + str(a) + "-" + str(b) + " is overlapping with " + str(subTA) + "-" + str(subTB) + ". on the left, between " + str(a) + " and " + str(subTB) + '.' 
            if((binaryMB != [1,1,0,0]) and (binaryMB != [0,0,1,1])):
                gateB=False
                if(binaryMB == [0,1,1,0]):
                    resultsB+="\n--TYPE TWO at : " + str(a) + "-" + str(b) + " SNP is encapsulated within " + str(subMA) + "-" + str(subMB) + '.'
                elif(binaryMB == [1,1,1,1]):
                    resultsB+="\n--TYPE TWO at : " + str(a) + "-" + str(b) + " is equal or encapsulating " + str(subMA) + "-" + str(subMB) + '.'
                elif((binaryMB == [1,1,1,0]) or (binaryMB == [0,1,1,1])):
                    if(binaryMB == [1,1,1,0]):
                        resultsB+="\n--TYPE TWO at : " + str(a) + "-" + str(b) + " is overlapping with " + str(subMA) + "-" + str(subMB) + ". on the right, between " + str(b) + " and " + str(subMA) + '.'
                    elif(binaryMB == [0,1,1,1]):
                        resultsB+="\n--TYPE TWO at : " + str(a) + "-" + str(b) + " is overlapping with " + str(subMA) + "-" + str(subMB) + ". on the left, between " + str(a) + " and " + str(subMB) + '.' 
    if(gateA):
        resultsA+="\nNo Type ONE window overlaps detected.\n"
    if(gateB):
        resultsB+="\nNo Type TWO window overlaps detected.\n"
    results += resultsA + "\n" + resultsB + "\n"
    results += "\nEND OF INTERVAL CHECKS.\nXXXXXXXXXXXXXXXXXXXXXX\n"
    with open(baseOut + projectName + "_" + "WindowOverlap.txt", 'a+') as window:
        window.write(results)
        
def bashInputs():
    outputLoc=str(os.environ['outputLoc'])
    filename=str(os.environ['filename'])
    interval=int(os.environ['interval'])
    inputFile=str(os.environ['inputFile'])
    projectName=str(os.environ['projectName'])
    geneDir=str(os.environ['geneDir'])
    baseOut=str(os.environ['baseOut'])
    sndMode=int(os.environ["sndMode"])
    return(outputLoc, filename, interval, inputFile, projectName, geneDir, baseOut, sndMode)

def main():
    outputLoc, filename, interval, inputFile, projectName, geneDir, baseOut, sndMode = bashInputs()
    if(sndMode != 1):
        bedType="BED_SPLIT/"
    else:
        bedType="BED_SPLIT/SND_BED/"
    masterList = bedMapper(interval, outputLoc, projectName, filename, geneDir, sndMode, bedType)
    binaryIntersect(masterList, interval, outputLoc, projectName, filename, geneDir, baseOut)
main()

END_OF_PYTHON

}

#    Split up file based on mutation direction
vcfSplit(){
    inputFile="${projectDic["inputFile"]}" baseOut="${projectDic["outputLoc"]}" outputLoc="${projectDic["tempOut"]}" filename="${projectDic["filename"]}" projectName="${projectDic["projectName"]}" sndMode="${projectDic["sndMode"]}" pypy3.6 - <<VCF_SPLIT_END

# import os
import os
import re
import subprocess

def geneDirCreate():
    geneDir={

        'AtoC':bytearray(),
        'AtoG':bytearray(),
        'AtoT':bytearray(),
        'CtoA':bytearray(),
        'CtoG':bytearray(),
        'CtoT':bytearray(),
        'GtoA':bytearray(),
        'GtoC':bytearray(),
        'GtoT':bytearray(),
        'TtoA':bytearray(),
        'TtoC':bytearray(),
        'TtoG':bytearray(),
        'rejected':bytearray(),
        'header':bytearray(),
        
    }

    SNDGeneDir={

        'AtoT':bytearray(),
        'CtoT':bytearray(),
        'GtoT':bytearray(),
        'TtoA':bytearray(),

    }
    return(geneDir, SNDGeneDir)

def vcfSegmentsOld(inputFile, geneDir, SNDGeneDir, sndMode):
    with open(inputFile, "rb") as raw:
        sub=[]
        counter=0
        gene=''
        results=''
        for readLine in raw:
            sub.clear()
            gene=''
            results=''
            gate=True
            counter=0
            while((gate == True) and (counter <= len(readLine))):
                element = chr(readLine[counter])
                if((element != '#') or (chr(readLine[0]) != "#")):                                
                    if((element != '\t') and (element != '\n')):
                        results = results + element
                    elif((element == '\t') and (element != '\n')):
                        sub.append(results)
                        sub.append(element)
                        results=''
                    if((element == "\n") or (len(sub) == 9)):
                        gene= str(sub[6]) + "to" + str(sub[8])
                        if gene in geneDir:
                            geneDir[gene].extend(readLine)
                            sub.clear()
                            gate=False
                        else:
                            if((sndMode == 1) and (len(sub[6]) >= 2)):
                                if(sub[6][1] != "T"):
                                    sub[6] = sub[6][1]
                                    sub[8] = "T"
                                    sub[2] = str(int(sub[2]) + 1)
                                else:
                                    sub[6] = sub[6][1]
                                    sub[8] = "A"
                                    sub[2] = str(int(sub[2]) + 1)
                                gene = str(sub[6]) + "to" + str(sub[8])
                                sub.append(results)
                                sub.append(element)
                                SNDGeneDir[gene].extend(''.join(sub).encode("utf-8"))
                                gate=False
                            else:
                                geneDir['rejected'].extend(readLine)
                                sub.clear()
                                gate=False
                else:
                    geneDir['header'].extend(readLine)
                    gate=False
                counter+=1
    return(geneDir, SNDGeneDir)

def vcfSegments(inputFile, geneDir, SNDGeneDir, sndMode):
    output = str(subprocess.check_output(['wc', '-m', inputFile]))
    length = re.findall(r'\d+', output)
    length = int(length[0])
    with open(inputFile, "rb") as raw:
        sub=[]
        gene=''
        results=''
        for counter in range(length):
            element = raw.read(1).decode("ascii")
            if(element != '#'):
                if((element != '\t') and (element != '\n')):
                    results = results + element
                elif((element == '\t') and (element != '\n')):
                    sub.append(results)
                    # sub.append(element)
                    results=''
                if(len(sub) >= 5):
                    # print(sub)
                    gene = str(sub[3]) + "to" + str(sub[4])
                    if gene in geneDir:
                        # print(gene)
                        # geneDir[gene].extend(readLine)
                        # geneDir[gene].extend('\t'.join(sub).encode("utf-8") + b'\t' + raw.readline())
                        geneDir[gene].extend('\t'.join(sub).encode("utf-8") + raw.readline())
                        # geneDir[gene].extend(raw.readline())
                        sub.clear()
                    else:
                        # print(sub[3])
                        if((sndMode == 1) and (len(sub[3]) >= 2)):
                            if(sub[3][1] != "T"):
                                sub[3] = sub[3][1]
                                sub[4] = "T"
                                sub[1] = str(int(sub[1]) + 1)
                            else:
                                sub[3] = sub[3][1]
                                sub[4] = "A"
                                sub[1] = str(int(sub[1]) + 1)
                            gene = str(sub[3]) + "to" + str(sub[4])
                            sub.append(results)
                            # print("SOUTH HAMPTON!!!")
                            SNDGeneDir[gene].extend('\t'.join(sub).encode("utf-8") + raw.readline())
                            # SNDGeneDir[gene].extend(raw.readline())
                            gene=''
                            results=''
                            sub.clear()
                        else:
                            sub.append(results)
                            geneDir['rejected'].extend('\t'.join(sub).encode("utf-8") + raw.readline())
                            gene=''
                            results=''
                            sub.clear()
            else:
                geneDir['header'].extend(element.encode("utf-8") + raw.readline())
    return(geneDir, SNDGeneDir)


def vcfSpliter(outputLoc, filename, baseOut, geneDir, SNDGeneDir, sndMode):
    for key in geneDir:
        if(geneDir[key]):
            if((key != "rejected") and (key != "header")):
                with open(outputLoc + "SPLITVCF/" + key + "_split_" + filename + ".vcf","ab") as vcfOut:
                    vcfOut.write(geneDir['header'])
                    vcfOut.write(geneDir[key])
            else:
                if(key != "header"):
                    with open(baseOut + "REJECTEDVCFs_" + filename + ".vcf","ab") as vcfOut:
                        vcfOut.write(geneDir['header'])
                        vcfOut.write(geneDir[key])
    if(sndMode == 1):
        for sndKey in SNDGeneDir:
            if(SNDGeneDir[sndKey]):
                with open(outputLoc + "SPLITVCF/SND_VCF/" + sndKey + "_split_" + filename + ".vcf","ab") as vcfOut:
                    vcfOut.write(geneDir['header'])
                    vcfOut.write(SNDGeneDir[sndKey])

def bashImport():
    outputLoc=str(os.environ['outputLoc'])
    inputFile=str(os.environ['inputFile'])
    filename=str(os.environ['filename'])
    projectName=str(os.environ['projectName'])
    baseOut=str(os.environ['baseOut'])
    sndMode=int(os.environ['sndMode'])
    return(projectName, inputFile, outputLoc, filename, baseOut, sndMode)

def main():
    projectName, inputFile, outputLoc, filename, baseOut, sndMode=bashImport()
    geneDir, SNDGeneDir=geneDirCreate()
    geneDir, SNDGeneDir=vcfSegments(inputFile, geneDir, SNDGeneDir, sndMode)
    vcfSpliter(outputLoc, filename, baseOut, geneDir, SNDGeneDir, sndMode)

main()

VCF_SPLIT_END

}
#    Looks for indel percentage in fasta output windows
#    If indel percentage is greater than desired, fasta entry is removed
fastaScanner(){

    inputFile="${projectDic["inputFile"]}" flank="${projectDic["flanks"]}" baseOut="${projectDic["outputLoc"]}" outputLoc="${projectDic["tempOut"]}" filename="${projectDic["filename"]}" geneTwo=${geneTwo} geneDirTwo="${geneDirTwo}" nMax="${projectDic["nMax"]}" windowLength="${projectDic["windowLength"]}" pypy3.6 - <<FASTA_SWEEP
    
from itertools import chain
import os

def fastaMapper(gene):
    with open(gene ,"rb") as fasta:
        fastafile=fasta.read()
        totalN=0
        master=[]
        sub=[]
        final=''
        for counter, i in enumerate(fastafile):
            element=chr(i)
            if(element == 'N'):
                totalN+=1
            if((element != "\n") and (element != ">")):
                final = final + str(element)
            if((element == "\n") and (element != ">")):
                final = final + str(element)
                sub.append(final)
                final=''
            if((element == ">") and (element != "\n")):
                if(sub != []):
                    if(sub[0] != ">"):
                        sub = [u.upper() for u in sub]
                    master.append(sub)
                    sub=[]
                    final=''
                    final = final + str(element)
                else:
                    final = final + str(element)
            if(counter == (len(fastafile)-1)):
                final = final + str(element)
                sub.append(final)
                master.append(sub)
    return(master)

def fastaNpop(subMaster, allRejected, nMax):
    maxP=nMax/100
    newsubMaster=[]
    nMaxList=[]
    for subListing in subMaster:
        totalN = len([x for x in subListing[1] if x == "N"])
        nPercent=totalN/len(subListing[1])
        if(nPercent >= maxP):
            nMaxList.append(subListing)
        else:
            newsubMaster.append(subListing)
    return(newsubMaster, nMaxList)

def fastaBasePop(master, interval, flank):
    allRejected=False
    subMaster=[]
    nList=[]
    if(interval > 2):
        Linterval=interval - flank ##change to 4
        Rinterval=interval - (flank - 1) ##change to 4
    else:
        Linterval=0 ##change to 4
        Rinterval=-1 ##change to 4
    for element in master: ##CHANGE TO SUBTRACT CORRECT DISTANCES
        baseIn = element[1][(Linterval):-(Rinterval)] ##MAYBE add +1 on Rinterval.
        if("N" not in baseIn):
            subMaster.append(element)
        else:
            nList.append(element)
    if(len(subMaster) == 0):
        allRejected=True
    return(subMaster, allRejected, nList)

def fileSaver(subMaster, master, nList, nMaxList, gene, allRejected, baseOut, filename, geneDirTwo, outputLoc):
    if(allRejected != True):
        with open(gene,"w") as newFasta:
            output="".join(chain.from_iterable(subMaster))
            newFasta.write(output)
    else:
        with open(baseOut + "FASTA_SPLIT/" + geneDirTwo + filename + ".fasta","w") as newFasta:
            output="".join(chain.from_iterable(master))
            newFasta.write(output)
        os.rename(outputLoc + "FASTA_SPLIT/" + geneDirTwo + filename + ".fasta", outputLoc + "ALLREJECTED_" + geneDirTwo + "_" + filename + ".fasta")
    if(len(nList) != 0):
        with open(baseOut + "N-BASE_FAILED_FASTAS.fasta","a") as newFasta:
            output="".join(chain.from_iterable(nList))
            newFasta.write(output)
    if(len(nMaxList) != 0):
        with open(baseOut + "N-THRESHOLD_FAILED_FASTAS.fasta","a") as newFasta:
            output="".join(chain.from_iterable(nMaxList))
            newFasta.write(output)

def bashImport():
    outputLoc=str(os.environ['outputLoc'])
    flank=int(os.environ['flank'])
    filename=str(os.environ['filename'])
    gene=str(os.environ['geneTwo'])
    nMax=int(os.environ['nMax'])
    geneDirTwo=str(os.environ['geneDirTwo']) ##GENE Direction
    interval=int(os.environ['windowLength'])
    baseOut=str(os.environ['baseOut'])
    return(flank, outputLoc, filename, gene, geneDirTwo, interval, nMax, baseOut)

def main():
    flank, outputLoc, filename, gene, geneDirTwo, interval, nMax, baseOut = bashImport()
    master=fastaMapper(gene)
    subMaster, allRejected, nList = fastaBasePop(master, interval, flank)
    subMaster, nMaxList = fastaNpop(subMaster, allRejected, nMax)
    fileSaver(subMaster, master, nList, nMaxList, gene, allRejected, baseOut, filename, geneDirTwo, outputLoc)

main()

FASTA_SWEEP

}
#    Creates a PBS job
#    Demonstrates that Corey can write more verbose code than Paul! Quite a victory!
jobCreatorPBS(){
    if [[ ${projectDic["isCmd"]} == "false" ]]; then
        local config="$@"
    else
        local config="none"
    fi
    myEmail="${projectDic["email"]}" job_specs="${job_specs}" scriptPath="${scriptPath}" nMax="${projectDic["nMax"]}" allData="${projectDic["allData"]}" inputFile="${projectDic["inputFile"]}" \
    outputLoc="${projectDic["outputLoc"]}" projectName="${projectDic["projectName"]}" windowLength="${projectDic["windowLength"]}" flanks="${projectDic["flanks"]}" referenceGenome="${projectDic["referenceGenome"]}" \
    s3="${projectDic["s3"]}" msi="${projectDic["msi"]}" dpb="${projectDic["dropbox"]}" dpba="${projectDic["dropboxAuth"]}" gh="${projectDic["github"]}" ghu="${projectDic["gitUser"]}" ghp="${projectDic["gitPass"]}" \
    gho="${projectDic["owner"]}" ghr="${projectDic["Myrepository"]}" config="${config}" ma="${projectDic["mutationAnalysis"]}" nbrs="${projectDic["nbrOrSpec"]}" sndMode="${projectDic["sndMode"]}"\
    symas="${projectDic["symOrAsy"]}" queue="${projectDic["queue"]}" graphs="${projectDic["graphs"]}" python3.6 - <<JOB_CREATED


import os

def jobScript(projectName, inputFile, windowLength, referenceGenome, flanks, email, outputLoc, allData, nMax, scriptPath, job_specs, s3, msi, dpb, dpba, gh, ghu, ghp, gho, ghr, config, ma, nbrs, symas, queue, graphs, sndMode):
    job="#!/bin/bash -l\n\n#PBS -l " + job_specs + "\n#PBS -m abe\n#PBS -M " + email + "\n"
    job+="#PBS -N " + projectName + "\n"
    job+="#PBS -o " + outputLoc + "\n#PBS -e " + outputLoc + "\n#PBS -q " + queue + "\n\n"
    
    job+= scriptPath + "/SNPcontext "
    job+= "-i " + inputFile + " "
    job+= "-o " + outputLoc + " "
    job+= "-w " + windowLength + " "
    job+= "-f " + flanks + " "
    job+= "-p " + projectName + " "
    job+= "-r " + referenceGenome + " "
    job+= "-ad " + allData + " "
    job+= "-n " + nMax + " "
    job+= "-ma " + ma + " "
    job+= "-nbrs " + nbrs + " "
    job+= "-symas " + symas + " "
    job+= "-graphs " + graphs + " "
    job+= "-snd " + sndMode + " "

    job+= "-s3 " + s3 + " "
    job+= "-msi " + msi + " "
    job+= "-dpb " + dpb + " "
    job+= "-dpba " + dpba + " "
    job+= "-gh " + gh + " "
    job+= "-ghu " + ghu + " "
    job+= "-ghp " + ghp + " "
    job+= "-gho " + gho + " "
    job+= "-ghr " + ghr + " "

    job+= "-JOB THIS_IS_A_JOB "
    job+= "-CONFIGLOC " + config

    with open(outputLoc + projectName + ".job", "w") as jobScript:
        jobScript.write(job)

def bashImport():
    outputLoc=str(os.environ['outputLoc'])
    job_specs=str(os.environ['job_specs'])
    email=str(os.environ['myEmail'])
    flanks=str(os.environ['flanks'])
    config=str(os.environ['config'])
    scriptPath=str(os.environ['scriptPath'])
    referenceGenome=str(os.environ['referenceGenome'])
    windowLength=str(os.environ['windowLength'])
    inputFile=str(os.environ['inputFile'])
    projectName=str(os.environ['projectName'])
    allData=str(os.environ['allData'])
    nMax=str(os.environ['nMax'])
    ma=str(os.environ['ma'])
    nbrs=str(os.environ['nbrs'])
    symas=str(os.environ['symas'])
    queue=str(os.environ['queue'])
    graphs=str(os.environ['graphs'])
    sndMode=str(os.environ["sndMode"])

    s3=str(os.environ['s3'])
    msi=str(os.environ['msi'])
    dpb=str(os.environ['dpb'])
    dpba=str(os.environ['dpba'])
    gh=str(os.environ['gh'])
    ghu=str(os.environ['ghu'])
    ghp=str(os.environ['ghp'])
    gho=str(os.environ['gho'])
    ghr=str(os.environ['ghr'])

    return(projectName, inputFile, windowLength, referenceGenome, flanks, email, outputLoc, allData, nMax, scriptPath, job_specs, s3, msi, dpb, dpba, gh, ghu, ghp, gho, ghr, config, ma, nbrs, symas, queue, graphs, sndMode)

def main():
    projectName, inputFile, windowLength, referenceGenome, flanks, email, outputLoc, allData, nMax, scriptPath, job_specs, s3, msi, dpb, dpba, gh, ghu, ghp, gho, ghr, config, ma, nbrs, symas, queue, graphs, sndMode= bashImport()
    jobScript(projectName, inputFile, windowLength, referenceGenome, flanks, email, outputLoc, allData, nMax, scriptPath, job_specs, s3, msi, dpb, dpba, gh, ghu, ghp, gho, ghr, config, ma, nbrs, symas, queue, graphs, sndMode)

main()
    
JOB_CREATED

echo -e ""

qsub "${projectDic["outputLoc"]}""${projectDic["projectName"]}".job
echo -e "PBS job submitted.\nEXITING...\n"
exit 2

}

#    Creates a Slurm job script
#    Demonstrates that Corey can write more verbose code than Paul! Quite a victory!
jobCreatorSlurm(){
    if [[ ${projectDic["isCmd"]} == "false" ]]; then
        local config="$@"
    else
        local config="none"
    fi
    myEmail="${projectDic["email"]}" scriptPath="${scriptPath}" nMax="${projectDic["nMax"]}" allData="${projectDic["allData"]}" inputFile="${projectDic["inputFile"]}" \
    outputLoc="${projectDic["outputLoc"]}" projectName="${projectDic["projectName"]}" windowLength="${projectDic["windowLength"]}" flanks="${projectDic["flanks"]}" referenceGenome="${projectDic["referenceGenome"]}" \
    dpb="${projectDic["dropbox"]}" dpba="${projectDic["dropboxAuth"]}" gh="${projectDic["github"]}" ghu="${projectDic["gitUser"]}" ghp="${projectDic["gitPass"]}" \
    gho="${projectDic["owner"]}" ghr="${projectDic["Myrepository"]}" config="${config}" ma="${projectDic["mutationAnalysis"]}" nbrs="${projectDic["nbrOrSpec"]}" sndMode="${projectDic["sndMode"]}"\
    symas="${projectDic["symOrAsy"]}" graphs="${projectDic["graphs"]}" time="${projectDic["job-time"]}" nodes="${projectDic["job-nodes"]}" memory="${projectDic["job-memory"]}" \
    memory_per_CPU="${projectDic["job-memPerCPU"]}" cpus_per_task="${projectDic["job-cpuPerTask"]}" s3="${projectDic["s3"]}" msi="${projectDic["msi"]}" python3.6 - <<JOB_CREATED


import os

def jobScript(projectName, inputFile, windowLength, referenceGenome, flanks, email, outputLoc, allData, nMax, scriptPath, dpb, dpba, s3, msi, gh, ghu, ghp, gho, ghr, config, ma, nbrs, symas, graphs, sndMode, time, nodes, memory, memory_per_CPU, cpus_per_task):

    job = "#!/bin/bash\n"
    job += "#SBATCH --job-name=" + projectName + "\n"  
    job += "#SBATCH --output=" + outputLoc + "\n"  
    job += "#SBATCH --mail-user=" + email + "\n"  
    job += "#SBATCH --time=" time + "\n"   	
    job += "#SBATCH --nodes=" + nodes + "\n"                    
    job += "#SBATCH --mem=" + memory + "\n" 
    job += "#SBATCH --mem-per-cpu=" + memory_per_CPU + "\n"                    
    job += "#SBATCH --cpus-per-task=" + cpus_per_task + "\n"                    
                   
    job+= scriptPath + "/SNPcontext "
    job+= "-i " + inputFile + " "
    job+= "-o " + outputLoc + " "
    job+= "-w " + windowLength + " "
    job+= "-f " + flanks + " "
    job+= "-p " + projectName + " "
    job+= "-r " + referenceGenome + " "
    job+= "-ad " + allData + " "
    job+= "-n " + nMax + " "
    job+= "-ma " + ma + " "
    job+= "-nbrs " + nbrs + " "
    job+= "-symas " + symas + " "
    job+= "-graphs " + graphs + " "
    job+= "-snd " + sndMode + " "

    job+= "-s3 " + s3 + " "
    job+= "-msi " + msi + " "
    job+= "-dpb " + dpb + " "
    job+= "-dpba " + dpba + " "
    job+= "-gh " + gh + " "
    job+= "-ghu " + ghu + " "
    job+= "-ghp " + ghp + " "
    job+= "-gho " + gho + " "
    job+= "-ghr " + ghr + " "

    job+= "-JOB THIS_IS_A_JOB "
    job+= "-CONFIGLOC " + config

    with open(outputLoc + projectName + ".sbatch", "w") as jobScript:
        jobScript.write(job)

def bashImport():
    outputLoc=str(os.environ['outputLoc'])
    email=str(os.environ['myEmail'])
    flanks=str(os.environ['flanks'])
    config=str(os.environ['config'])
    scriptPath=str(os.environ['scriptPath'])
    referenceGenome=str(os.environ['referenceGenome'])
    windowLength=str(os.environ['windowLength'])
    inputFile=str(os.environ['inputFile'])
    projectName=str(os.environ['projectName'])
    allData=str(os.environ['allData'])
    nMax=str(os.environ['nMax'])
    ma=str(os.environ['ma'])
    nbrs=str(os.environ['nbrs'])
    symas=str(os.environ['symas'])
    graphs=str(os.environ['graphs'])
    sndMode=str(os.environ["sndMode"])

    dpb=str(os.environ['dpb'])
    dpba=str(os.environ['dpba'])
    gh=str(os.environ['gh'])
    ghu=str(os.environ['ghu'])
    ghp=str(os.environ['ghp'])
    gho=str(os.environ['gho'])
    ghr=str(os.environ['ghr'])

    s3=str(os.environ['s3'])
    msi=str(os.environ['msi'])

    time=str(os.environ['time'])
    nodes=str(os.environ['nodes'])
    memory=str(os.environ['memory'])
    memory_per_CPU=str(os.environ['memory_per_CPU'])
    cpus_per_task=str(os.environ['cpus_per_task'])

    return(projectName, inputFile, windowLength, referenceGenome, flanks, email, outputLoc, allData, nMax, scriptPath, s3, msi, dpb, dpba, gh, ghu, ghp, gho, ghr, config, ma, nbrs, symas, graphs, sndMode, time, nodes, memory, memory_per_CPU, cpus_per_task)

def main():
    projectName, inputFile, windowLength, referenceGenome, flanks, email, outputLoc, allData, nMax, scriptPath, s3, msi, dpb, dpba, gh, ghu, ghp, gho, ghr, config, ma, nbrs, symas, graphs, sndMode,  time, nodes, memory, memory_per_CPU, cpus_per_task = bashImport()
    jobScript(projectName, inputFile, windowLength, referenceGenome, flanks, email, outputLoc, allData, nMax, scriptPath, s3, msi, dpb, dpba, gh, ghu, ghp, gho, ghr, config, ma, nbrs, symas, queue, graphs, sndMode, time, nodes, memory, memory_per_CPU, cpus_per_task)

main()
    
JOB_CREATED

echo -e ""

sbatch "${projectDic["outputLoc"]}""${projectDic["projectName"]}".sbatch
echo -e "Slurm job submitted.\nEXITING...\n"
exit 2

}

jobCreatorTest(){
    if [[ ${projectDic["isCmd"]} == "false" ]]; then
        local config="$@"
    else
        local config="none"
    fi

    # echo -e "Whats my Price?"
    # echo -e "${scriptPath}"

    echo -e ""

qsub <<EndofSubmission
    
    #PBS -l "${job_specs}"
    #PBS -M "${projectDic["email"]}"
    #PBS -N "${projectDic["projectName"]}"
    #PBS -o "${projectDic["outputLoc"]}"
    #PBS -e "${projectDic["outputLoc"]}"
    #PBS -m abe
    #PBS -q "${projectDic["queue"]}"

    "${scriptPath}"/SNPcontext -i "${projectDic["inputFile"]}" -o "${projectDic["outputLoc"]}" -w "${projectDic["windowLength"]}" -f "${projectDic["flanks"]}" -p "${projectDic["projectName"]}" -r "${projectDic["referenceGenome"]}" -ad "${projectDic["allData"]}" -n "${projectDic["nMax"]}" -JOB THIS_IS_A_JOB -msi "${projectDic["msi"]}" -dpb "${projectDic["dropbox"]}" -dpba "${projectDic["dropboxAuth"]}" -gh "${projectDic["github"]}" -ghu "${projectDic["gitUser"]}" -ghp "${projectDic["gitPass"]}" -gho "${projectDic["owner"]}" -s3 "${projectDic["s3"]}" -ghr "${projectDic["Myrepository"]}" -CONFIGLOC "${config}"
    
EndofSubmission

    echo -e "Job submitted...\nEXITING...\n"
    exit 2
}

#    This is the primary function
mainOld(){
    config_check "$@"
    if [[ "${projectDic["JOB"]}" != "THIS_IS_A_JOB" ]] && [[ "${projectDic["msi"]}" == 'true' ]]; then
        # echo -e "${projectDic["JOB"]}"
        # echo -e "${projectDic["msi"]}"
        module load python3_ML/3.6.4
        jobCreator "$@"
    fi
    moduleLoader ##LOADS CORRECT MODULES        
    dirStructure
    vcfSplit
    fileConverter ##MAKES BED FILE
    # local temp="${projectDic["tempOut"]}"BED_SPLIT/
    # local splitDir=("${temp}"*_split_"${projectDic[filename]}".bed*)
    # for gene in "${splitDir[@]}"; do
    #     local geneDir="${gene%.*}"
    #     geneDir="${geneDir##*/}"
    #     geneDir=${geneDir:0:4} ##BASH IS BASE 1
	#     sndLocal=0
    #     pythonBEDScanner "$geneDir" "$sndLocal" & ##EXPANDS BED FILE WINDOWS AND CHECKS FOR OVER LAP
    # done
    # wait
    if [[ "${projectDic["sndMode"]}" -eq 1 ]]; then
    	local temp="${projectDic["tempOut"]}"BED_SPLIT/SND_BED/  
        local splitDir=("${temp}"*_split_"${projectDic[filename]}".bed*)
        for gene in "${splitDir[@]}"; do
            local geneDir="${gene%.*}"
            geneDir="${geneDir##*/}"
            geneDir=${geneDir:0:4} ##BASH IS BASE 1
            sndLocal=1
            pythonBEDScanner "$geneDir" "$sndLocal" & ##EXPANDS BED FILE WINDOWS AND CHECKS FOR OVER LAP
        done
        wait
    fi
    echo -e "\nOverlap checks completed..."
    echo -e "See overlap results located in 'WindowOverlap.txt' in your main output directory.\n"
    # fileConverter ##CREATES FASTA FILE
    # local tempTwo="${projectDic["tempOut"]}"FASTA_SPLIT/
    # local fastalisting=("${tempTwo}"*_"${projectDic[filename]}".fasta*)
    # for geneTwo in "${fastalisting[@]}"; do
    #     local geneDirTwo="${geneTwo%.*}"
    #     geneDirTwo="${geneDirTwo##*/}"
    #     geneDirTwo=${geneDirTwo:0:4}
    #     fastaScanner "${geneDirTwo}" "${geneTwo}" & ##COPIES MASTER FASTA FILE 12 TIMES FOR ALN_TO_COUNTS
    # done
    # wait
    if [[ "${projectDic["sndMode"]}" -eq 1 ]]; then
        local tempTwo="${projectDic["tempOut"]}"FASTA_SPLIT/SND_FASFA/
        local fastalisting=("${tempTwo}"*_"${projectDic[filename]}".fasta*)
        for geneTwo in "${fastalisting[@]}"; do
            local geneDirTwo="${geneTwo%.*}"
            geneDirTwo="${geneDirTwo##*/}"
            geneDirTwo=${geneDirTwo:0:4}
            fastaScanner "${geneDirTwo}" "${geneTwo}" & ##COPIES MASTER FASTA FILE 12 TIMES FOR ALN_TO_COUNTS
        done
        wait
    fi
    fileConverter ##ALN_TO_COUNTS TABLES WHICH ARE FED INTO ALL_COUNTS
    fileConverter ##ALL_COUNTS
    if [[ "${projectDic["allData"]}" == "false"  ]]; then
        local templocation="${projectDic["TempLoc"]}"
        rm -rf "${templocation}"
    fi
    if [[ "${projectDic["s3"]}" -gt 0 ]]; then
        # echo -e "TEST"
        # echo -e "${projectDic["s3"]}\n"
        s3Saver "$@"
    fi
    if [[ "${projectDic["dropbox"]}" == 'true' ]]; then
        dropboxSaver "$@"
    fi
    if [[ "${projectDic["github"]}" == 'true' ]]; then
        gitHubSaver "$@"
    fi
    echo -e "Operations completed...\n"
    exit 0
}


main(){
    config_check "$@"
    ## Older-Implementation
    ##if [[ "${projectDic["JOB"]}" != "THIS_IS_A_JOB" ]] && [[ "${projectDic["msi"]}" == 'true' ]]; then
    ##    module load python3_ML/3.6.4
    ##    jobCreator "$@"
    ##fi
    ##moduleLoader ##LOADS CORRECT MODULES   
    if [[ "${projectDic["JOB"]}" != "THIS_IS_A_JOB" ]] && [[ "${projectDic["job_scheduler"]}" == 'true' ]]; then
        if [[ "${projectDic["msi"]}" == 'true' ]]; then
            module load python3_ML/3.6.4
        fi
        ## Checks if system has Python 3.6 or greater installed 
        if [[ $(python3 -c 'import sys; print(sys.version_info[0:2])') != '(3, 6)' ]]; then
                echo -e "Python version out of date. Please install Python 3.6.x to submit job.\n"
                ##exit 1 # May not need an exit here
        else
            if [[ "${projectDic["schedulerMode"]}" -eq 1 ]]; then
                jobCreatorSlurm "$@"
            else if [[ "${projectDic["schedulerMode"]}" -eq 2 ]]; then
                jobCreatorPBS "$@"
            else
                echo -e "Invalid job scheduler selector - please update the config file. 1 = slurm and 2 = PBS\n"
                exit 1
            fi
        fi
    fi
    moduleLoader ##LOADS CORRECT MODULES       
    dirStructure
    vcfSplit

    cd "${projectDic["tempOut"]}"SPLITVCF/
    sndAmount=$(find . -maxdepth 1 -type f -name "*.vcf" | wc -l)
    if [[ ${sndAmount} != 0 ]]; then
        fileConverterMode="SPLITVCF/"
        fileConverterTemp="BED_SPLIT/"
        fileConverter "${fileConverterMode}"  "${fileConverterTemp}" ##MAKES BED FILE
        local temp="${projectDic["tempOut"]}"BED_SPLIT/
        local splitDir=("${temp}"*_split_"${projectDic[filename]}".bed*)
        sndLocal=0
        for gene in "${splitDir[@]}"; do
            local geneDir="${gene%.*}"
            geneDir="${geneDir##*/}"
            geneDir=${geneDir:0:4} ##BASH IS BASE 1
            pythonBEDScanner "$geneDir" "$sndLocal" & ##EXPANDS BED FILE WINDOWS AND CHECKS FOR OVER LAP
        done
        wait
        echo -e "\nOverlap checks completed..."
        echo -e "See overlap results located in 'WindowOverlap.txt' in your main output directory.\n"
        fileConverterMode="BED_SPLIT/"
        fileConverterTemp="FASTA_SPLIT/"
        fileConverter "${fileConverterMode}" "${fileConverterTemp}" ##CREATES FASTA FILE
        local tempTwo="${projectDic["tempOut"]}"FASTA_SPLIT/
        local fastalisting=("${tempTwo}"*_"${projectDic[filename]}".fasta*)
        for geneTwo in "${fastalisting[@]}"; do
            local geneDirTwo="${geneTwo%.*}"
            geneDirTwo="${geneDirTwo##*/}"
            geneDirTwo=${geneDirTwo:0:4}
            fastaScanner "${geneDirTwo}" "${geneTwo}" & ##COPIES MASTER FASTA FILE 12 TIMES FOR ALN_TO_COUNTS
        done
        wait
        fileConverterMode="FASTA_SPLIT/"
        fileConverterTemp="COUNTS_TABLES/"
        fileConverter "${fileConverterMode}" "${fileConverterTemp}" ##ALN_TO_COUNTS TABLES WHICH ARE FED INTO ALL_COUNTS
        fileConverter ##ALL_COUNTS
        fileConverterMode="COUNTS_TABLES/"
        fileConverterTemp="MUTATION_ANALYSIS/"
        fileConverter "${fileConverterMode}" "${fileConverterTemp}" ## MUTATION GRAPHING
        fileConverter ## MUTATION GRAPHING COMBINED
        active=()
    fi

    cd "${projectDic["tempOut"]}"SPLITVCF/SND_VCF/
    sndAmount=$(find . -type f -name "*.vcf" | wc -l)
    if [[ "${projectDic["sndMode"]}" -eq 1 ]] && [[ ${sndAmount} != 0 ]]; then
        projectDic[OperationalStage]="vcfTObed"
        fileConverterMode="SPLITVCF/SND_VCF/"
        fileConverterTemp="BED_SPLIT/SND_BED/"
        mkdir "${projectDic["tempOut"]}"BED_SPLIT/SND_BED/
        fileConverter "${fileConverterMode}" "${fileConverterTemp}" ##MAKES BED FILE
        local temp="${projectDic["tempOut"]}"BED_SPLIT/SND_BED/  
        local splitDir=("${temp}"*_split_"${projectDic[filename]}".bed*)
        sndLocal=1
        for gene in "${splitDir[@]}"; do
            local geneDir="${gene%.*}"
            geneDir="${geneDir##*/}"
            geneDir=${geneDir:0:4} ##BASH IS BASE 1
            pythonBEDScanner "$geneDir" "$sndLocal" & ##EXPANDS BED FILE WINDOWS AND CHECKS FOR OVER LAP
        done
        wait
        echo -e "\nOverlap checks on SNDs completed..."
        fileConverterMode="BED_SPLIT/SND_BED/"
        fileConverterTemp="FASTA_SPLIT/SND_FASFA/"
        mkdir "${projectDic["tempOut"]}"FASTA_SPLIT/SND_FASFA/
        fileConverter "${fileConverterMode}" "${fileConverterTemp}" ##CREATES FASTA FILE
        local tempTwo="${projectDic["tempOut"]}"FASTA_SPLIT/SND_FASFA/
        local fastalisting=("${tempTwo}"*_"${projectDic[filename]}".fasta*)
        for geneTwo in "${fastalisting[@]}"; do
            local geneDirTwo="${geneTwo%.*}"
            geneDirTwo="${geneDirTwo##*/}"
            geneDirTwo=${geneDirTwo:0:4}
            fastaScanner "${geneDirTwo}" "${geneTwo}" & ##COPIES MASTER FASTA FILE 12 TIMES FOR ALN_TO_COUNTS
        done
        wait
        fileConverterMode="FASTA_SPLIT/SND_FASFA/"
        fileConverterTemp="COUNTS_TABLES/SND_TABLES/"
        mkdir "${projectDic[outputLoc]}"COUNTS_TABLES/SND_TABLES
        mkdir "${projectDic[outputLoc]}"COUNTS_TABLES/SND_TABLES/LOGS
        fileConverter "${fileConverterMode}" "${fileConverterTemp}" ## ALN_TO_COUNTS TABLES WHICH ARE FED INTO ALL_COUNTS
        fileConverterMode="COUNTS_TABLES/SND_TABLES/"
        fileConverterTemp="MUTATION_ANALYSIS/SND_ANALYSIS/"
        mkdir "${projectDic[outputLoc]}"MUTATION_ANALYSIS/SND_ANALYSIS/
        projectDic["OperationalStage"]="graphSingle"
        fileConverter "${fileConverterMode}" "${fileConverterTemp}" ## MUTATION GRAPHING

    fi

    if [[ "${projectDic["allData"]}" == "false"  ]]; then
        local templocation="${projectDic["TempLoc"]}"
        rm -rf "${templocation}"
    fi
    if [[ "${projectDic["s3"]}" -gt 0 ]]; then
        # echo -e "TEST"
        # echo -e "${projectDic["s3"]}\n"
        s3Saver "$@"
    fi
    if [[ "${projectDic["dropbox"]}" == 'true' ]]; then
        dropboxSaver "$@"
    fi
    if [[ "${projectDic["github"]}" == 'true' ]]; then
        gitHubSaver "$@"
    fi
    echo -e "Operations completed...\n"
    exit 0
}

main "$@"
